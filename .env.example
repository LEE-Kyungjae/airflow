# ============================================================
# Airflow Crawler System - Environment Configuration
# ============================================================
#
# Copy this file to .env and fill in real values.
# Variables marked [REQUIRED] MUST be set for production.
# Variables marked [RECOMMENDED] SHOULD be set for production.
# Variables marked [OPTIONAL] have sensible defaults.
#
# SECURITY WARNING:
#   - Never commit .env to version control.
#   - Replace ALL "change-this-*" placeholder values.
#   - Use strong, unique secrets for each variable.
#   - Run `python .env.validator.py --production` before deploying.
# ============================================================


# ============================================================
# 1. CRITICAL SECRETS (must be changed for production)
# ============================================================

# [REQUIRED] Admin login password for the API
# Minimum 12 characters, use a strong random password
ADMIN_PASSWORD=change-this-to-a-strong-password

# [REQUIRED] JWT token signing secret
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(64))"
# Minimum 32 characters of high-entropy random data
JWT_SECRET_KEY=

# [REQUIRED] Airflow Fernet key for connection encryption
# Generate with: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
AIRFLOW_FERNET_KEY=

# [REQUIRED] MongoDB root password
# Minimum 12 characters, use a strong random password
MONGO_ROOT_USERNAME=crawlerAdmin
MONGO_ROOT_PASSWORD=change-this-to-a-strong-password

# [REQUIRED] PostgreSQL password
# Minimum 12 characters, use a strong random password
POSTGRES_USER=airflow
POSTGRES_PASSWORD=change-this-to-a-strong-password
POSTGRES_DB=airflow


# ============================================================
# 2. APPLICATION CONFIGURATION
# ============================================================

# [RECOMMENDED] Environment identifier
# Values: "production" or "development"
# Controls: error verbosity, security headers, CORS, debug mode
# ENV=production

# [RECOMMENDED] Authentication mode
# Values: "required" (default), "optional", "disabled" (dev only)
# "disabled" is blocked in production for safety
# AUTH_MODE=required

# [OPTIONAL] JWT token expiration (minutes)
# JWT_EXPIRE_MINUTES=60

# [OPTIONAL] JWT refresh token expiration (days)
# JWT_REFRESH_EXPIRE_DAYS=7

# [OPTIONAL] Log output format: "json" (production) or "console" (development)
# LOG_FORMAT=json

# [OPTIONAL] Log level: DEBUG, INFO, WARNING, ERROR
# LOG_LEVEL=INFO


# ============================================================
# 3. AIRFLOW CONFIGURATION
# ============================================================

# [RECOMMENDED] Airflow user ID (match host user for file permissions)
AIRFLOW_UID=50000

# [RECOMMENDED] Airflow web UI credentials
_AIRFLOW_WWW_USER_USERNAME=airflow
_AIRFLOW_WWW_USER_PASSWORD=change-this-password


# ============================================================
# 4. AI MODEL CONFIGURATION
# ============================================================

# [RECOMMENDED] OpenAI API key for AI-powered features
# Required for: auto-discovery, crawler generation, self-healing
OPENAI_API_KEY=your-openai-api-key-here

# [OPTIONAL] AI model to use (default: gpt-4o-mini)
AI_MODEL=gpt-4o-mini

# [OPTIONAL] Custom OpenAI-compatible API base URL
# Leave commented out for standard OpenAI API
# AI_BASE_URL=
# Examples:
#   GLM-4:    AI_BASE_URL=https://open.bigmodel.cn/api/paas/v4/  AI_MODEL=glm-4-flash
#   DeepSeek: AI_BASE_URL=https://api.deepseek.com              AI_MODEL=deepseek-chat
#   Qwen:     AI_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1  AI_MODEL=qwen-plus


# ============================================================
# 5. NETWORKING & SECURITY
# ============================================================

# [RECOMMENDED] CORS allowed origins (comma-separated)
# In production, list exact frontend domains. Never use "*".
# ALLOWED_ORIGINS=https://app.yourdomain.com,https://admin.yourdomain.com

# [RECOMMENDED] Trusted host names for production (comma-separated)
# ALLOWED_HOSTS=api.yourdomain.com,yourdomain.com

# [OPTIONAL] Redis URL for distributed rate limiting
# Required for multi-instance deployments
# REDIS_URL=redis://localhost:6379

# [OPTIONAL] Audit logging (default: enabled)
# AUDIT_LOG_ENABLED=true

# [OPTIONAL] Security header overrides (defaults are secure)
# SECURITY_X_FRAME_OPTIONS=DENY
# SECURITY_REFERRER_POLICY=strict-origin-when-cross-origin
# CONTENT_SECURITY_POLICY=default-src 'self'


# ============================================================
# 6. EMAIL / SMTP ALERTS
# ============================================================

# [RECOMMENDED] SMTP configuration for email alerts
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your-email@gmail.com
SMTP_PASSWORD=your-app-password
ALERT_EMAIL=alerts@yourdomain.com


# ============================================================
# 7. MONITORING
# ============================================================

# [RECOMMENDED] Grafana admin credentials
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=change-this-to-a-strong-password


# ============================================================
# 8. BACKUP CONFIGURATION
# ============================================================

# [OPTIONAL] Backup settings
BACKUP_RETENTION_DAYS=30
BACKUP_CLOUD_PROVIDER=local  # Options: local, s3, gcs, azure
BACKUP_COMPRESSION=true
BACKUP_VERIFY=true

# [OPTIONAL] AWS S3 configuration (required if BACKUP_CLOUD_PROVIDER=s3)
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
BACKUP_S3_BUCKET=your-backup-bucket
BACKUP_S3_PREFIX=mongodb-backups

# [OPTIONAL] Google Cloud Storage configuration (required if BACKUP_CLOUD_PROVIDER=gcs)
BACKUP_GCS_BUCKET=your-gcs-bucket
BACKUP_GCS_PREFIX=mongodb-backups
# Note: For GCS, set GOOGLE_APPLICATION_CREDENTIALS env var or use service account
